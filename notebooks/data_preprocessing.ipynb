{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Advanced Project\\\\Lesion-Stroke-Segmentation\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Advanced Project\\\\Lesion-Stroke-Segmentation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Steps\n",
    "* Re-size Images\n",
    "* Correct Orientation\n",
    "* Normalization\n",
    "* Image Augmentation\n",
    "    - Image Random Rotation\n",
    "    - Image Random Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataProcessingEntity:\n",
    "    training_data: Path\n",
    "    testing_data: Path\n",
    "    train_csv: Path\n",
    "    test_csv: Path\n",
    "    preprocess_train_in: Path\n",
    "    preprocess_train_op: Path\n",
    "    preprocess_test_in: Path\n",
    "    img_height: int\n",
    "    img_width: int\n",
    "    img_norms_range: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lesionSeg.constant import *\n",
    "from lesionSeg.Utils.common import read_yaml, create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, params = PARAMS_FILE_PATH, config = CONFIG_FILE_PATH):\n",
    "        self.params = read_yaml(params)\n",
    "        self.config = read_yaml(config)\n",
    "\n",
    "        create_directory([self.config.artifact_root])\n",
    "\n",
    "    def data_preprocessing_config(self) -> DataProcessingEntity:\n",
    "        params = self.params.image_preprocess\n",
    "        config = self.config.data_preprocessing\n",
    "\n",
    "        create_directory([config.root_dir, \n",
    "                          config.preprocess_train_in, \n",
    "                          config.preprocess_train_op, \n",
    "                          config.preprocess_test_in])\n",
    "\n",
    "        data_preprocessing_entity = DataProcessingEntity(\n",
    "            training_data = Path(config.training_data),\n",
    "            train_csv = Path(config.train_csv),\n",
    "            test_csv = Path(config.test_csv),\n",
    "            testing_data = Path(config.testing_data),\n",
    "            preprocess_train_in = Path(config.preprocess_train_in),\n",
    "            preprocess_train_op = Path(config.preprocess_train_op),\n",
    "            preprocess_test_in = Path(config.preprocess_test_in),\n",
    "            img_height = params.img_height,\n",
    "            img_width = params.img_width,\n",
    "            img_norms_range = params.img_norms_range\n",
    "        )\n",
    "        \n",
    "        return data_preprocessing_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "from bids import BIDSLayout\n",
    "from lesionSeg.logging import logger \n",
    "from lesionSeg.Exception.exception import CustomeException\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"nibabel\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, config: DataProcessingEntity):\n",
    "        self.config = config\n",
    "\n",
    "    def normalize_img(self, X):\n",
    "        \"\"\"\n",
    "        Normalize image intensities to the range specified in the config.\n",
    "        \"\"\"\n",
    "        alpha = self.config.img_norms_range[0]\n",
    "        beta = self.config.img_norms_range[1]\n",
    "        norm_img = cv2.normalize(X, dst=None, alpha=alpha, beta=beta, norm_type=cv2.NORM_MINMAX)\n",
    "        return norm_img\n",
    "    \n",
    "    def img_resize(self, X, label='input'):\n",
    "        \"\"\"\n",
    "        Resize an image to the target size specified in the config.\n",
    "        Uses Lanczos interpolation for input images and nearest neighbor for masks.\n",
    "        \"\"\"\n",
    "        img_size = (self.config.img_width, self.config.img_height)\n",
    "        if label == 'input':\n",
    "            resized_img = cv2.resize(X, dsize=img_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "        elif label == 'mask':\n",
    "            resized_img = cv2.resize(X, dsize=img_size, interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            raise ValueError(f\"Label -> {label} is Incorrect. Use 'input' or 'mask'.\")\n",
    "        return resized_img\n",
    "    \n",
    "    def train_df_process(self, df):\n",
    "        \"\"\"\n",
    "        Process the training dataframe by selecting the necessary columns and merging input and mask files.\n",
    "        \"\"\"\n",
    "        selected_cols = [\"path\", \"subject\"]\n",
    "        df_input = df[df['suffix'] == 'T1w'][selected_cols].rename({'path': 'og_input_path'}, axis=1)\n",
    "        df_mask = df[df['suffix'] == 'mask'][selected_cols].rename({'path': 'og_mask_path'}, axis=1)\n",
    "        updt_cols = ['og_input_path', 'og_mask_path', 'subject']\n",
    "        df_merge = df_input.merge(df_mask, on='subject', how='inner').reset_index(drop=True).reindex(columns=updt_cols)\n",
    "        return df_merge\n",
    "    \n",
    "    def test_df_process(self, df):\n",
    "        \"\"\"\n",
    "        Process the testing dataframe by selecting the necessary columns.\n",
    "        \"\"\"\n",
    "        selected_cols = [\"path\", \"subject\"]\n",
    "        df_input = df[df['suffix'] == 'T1w'][selected_cols].rename({'path': 'og_input_path'}, axis=1)\n",
    "        return df_input\n",
    "\n",
    "    def preprocess_train_dataset(self, n):\n",
    "        \"\"\"\n",
    "        Preprocess one training subject: load input and mask volumes, process each slice by resizing \n",
    "        and normalizing, then save the processed volumes as NIfTI images.\n",
    "        \"\"\"\n",
    "        X_path = n[\"og_input_path\"]\n",
    "        y_path = n[\"og_mask_path\"]\n",
    "        subject = n['subject']\n",
    "        \n",
    "        input_dir = self.config.preprocess_train_in\n",
    "        output_dir = self.config.preprocess_train_op\n",
    "        processed_input_path = os.path.join(input_dir, f\"{subject}_input.nii.gz\")\n",
    "        processed_mask_path = os.path.join(output_dir, f\"{subject}_mask.nii.gz\")\n",
    "\n",
    "        in_nib = nb.load(X_path)\n",
    "        mask_nib = nb.load(y_path)\n",
    "\n",
    "        ras_in = nb.as_closest_canonical(in_nib)\n",
    "        ras_mask = nb.as_closest_canonical(mask_nib)\n",
    "\n",
    "        # Get the data arrays and affine matrices.\n",
    "        X_img = ras_in.get_fdata()\n",
    "        y_img = ras_mask.get_fdata()\n",
    "        affine_input = ras_in.affine\n",
    "        affine_mask = ras_mask.affine \n",
    "\n",
    "        img_no = X_img.shape[2]\n",
    "        target_height = self.config.img_height\n",
    "        target_width  = self.config.img_width\n",
    "        \n",
    "        # Pre-allocate arrays for processed volumes.\n",
    "        processed_in_volume = np.empty((target_height, target_width, img_no), dtype=np.float32)\n",
    "        processed_mask_volume = np.empty((target_height, target_width, img_no), dtype=np.float32)\n",
    "\n",
    "        for i in range(img_no):\n",
    "            # Process input slice: resize (with label 'input') then normalize.\n",
    "            input_img_arr = X_img[:, :, i]\n",
    "            resized_input = self.img_resize(input_img_arr, label='input')\n",
    "            norm_input = self.normalize_img(resized_input)\n",
    "            processed_in_volume[:, :, i] = norm_input\n",
    "\n",
    "            # Process mask slice: resize using nearest neighbor (with label 'mask').\n",
    "            mask_img_arr = y_img[:, :, i]\n",
    "            resized_mask = self.img_resize(mask_img_arr, label='mask')\n",
    "            processed_mask_volume[:, :, i] = resized_mask\n",
    "\n",
    "        # Create new NIfTI images using the processed data and the original affines.\n",
    "        processed_in_nib = nb.Nifti1Image(processed_in_volume, affine_input)\n",
    "        processed_mask_nib = nb.Nifti1Image(processed_mask_volume, affine_mask)\n",
    "\n",
    "        nb.save(processed_in_nib, processed_input_path)\n",
    "        nb.save(processed_mask_nib, processed_mask_path)\n",
    "\n",
    "        return processed_input_path, processed_mask_path\n",
    "    \n",
    "    def preprocess_test_dataset(self, n):\n",
    "        \"\"\"\n",
    "        Preprocess one test subject: load input volume, process each slice by resizing and normalizing,\n",
    "        then save the processed volume as a NIfTI image.\n",
    "        \"\"\"\n",
    "        X_path = n[\"og_input_path\"]\n",
    "        subject = n['subject']\n",
    "\n",
    "        input_dir = self.config.preprocess_test_in\n",
    "        processed_input_path = os.path.join(input_dir, f\"{subject}_input.nii.gz\")\n",
    "\n",
    "        in_nib = nb.load(X_path)\n",
    "        ras_nib = nb.as_closest_canonical(in_nib)\n",
    "        X_img = ras_nib.get_fdata()\n",
    "        affine_input = in_nib.affine\n",
    "\n",
    "        img_no = X_img.shape[2]\n",
    "        target_height = self.config.img_height\n",
    "        target_width  = self.config.img_width\n",
    "        processed_in_volume = np.empty((target_height, target_width, img_no), dtype=np.float32)\n",
    "\n",
    "        for i in range(img_no):\n",
    "            input_img_arr = X_img[:, :, i]\n",
    "            resized_input = self.img_resize(input_img_arr, label='input')\n",
    "            norm_input = self.normalize_img(resized_input)\n",
    "            processed_in_volume[:, :, i] = norm_input\n",
    "        \n",
    "        processed_in_nib = nb.Nifti1Image(processed_in_volume, affine_input)\n",
    "        nb.save(processed_in_nib, processed_input_path)\n",
    "        return processed_input_path\n",
    "\n",
    "    def preprocess_dataset(self):\n",
    "        \"\"\"\n",
    "        Process the entire dataset by creating BIDS dataframes, processing training and test files,\n",
    "        and logging the locations of the processed data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            train_root = self.config.training_data\n",
    "            test_root = self.config.testing_data\n",
    "\n",
    "            train_layout = BIDSLayout(root=train_root, validate=False)\n",
    "            test_layout = BIDSLayout(root=test_root, validate=False)\n",
    "\n",
    "            train_df = train_layout.to_df()\n",
    "            logger.info(\"Training Dataframe has been Created\")\n",
    "            test_df = test_layout.to_df()\n",
    "            logger.info(\"Testing Dataframe has been Created\")\n",
    "\n",
    "            processed_train_df = self.train_df_process(train_df)\n",
    "            logger.info(\"Training Dataframe has been Pre-processed\")\n",
    "            processed_test_df = self.test_df_process(test_df)\n",
    "            logger.info(\"Testing Dataframe has been Pre-processed\")\n",
    "\n",
    "            processed_train_df[[\"processed_input_path\", \"processed_output_path\"]] = processed_train_df.apply(\n",
    "                lambda x: pd.Series(self.preprocess_train_dataset(x)), axis=1\n",
    "            )\n",
    "            logger.info(f\"Pre-Processed Input Training Data at: {self.config.preprocess_train_in}\")\n",
    "            logger.info(f\"Pre-Processed Mask Training Data at: {self.config.preprocess_train_op}\")\n",
    "\n",
    "            processed_test_df[\"processed_input_path\"] = processed_test_df.apply(\n",
    "                lambda x: self.preprocess_test_dataset(x), axis=1\n",
    "            )\n",
    "            logger.info(f\"Pre-Processed Input Testing Data at: {self.config.preprocess_test_in}\")\n",
    "            \n",
    "            train_csv_dir = self.config.train_csv\n",
    "            test_csv_dir = self.config.test_csv\n",
    "\n",
    "            processed_train_df.to_csv(train_csv_dir, index=False)\n",
    "            logger.info(f'Training Dataset CSV File at: {train_csv_dir}')\n",
    "            \n",
    "            processed_test_df.to_csv(test_csv_dir, index=False)\n",
    "            logger.info(f'Testing Dataset CSV File at: {test_csv_dir}')\n",
    "\n",
    "            logger.info(f\"Total Training Data Instance: {processed_train_df.shape[0]}\")\n",
    "            logger.info(f\"Total Testing Data Instance: {processed_test_df.shape[0]}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomeException(e, sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-07 23:03:54,500]: INFO: common : Read YAML File: params.yaml\n",
      "[2025-02-07 23:03:54,515]: INFO: common : Read YAML File: config\\config.yaml\n",
      "[2025-02-07 23:03:54,516]: INFO: common : Directory has been Created: artifact\n",
      "[2025-02-07 23:03:54,518]: INFO: common : Directory has been Created: artifact\\data_preprocessed\n",
      "[2025-02-07 23:03:54,520]: INFO: common : Directory has been Created: artifact\\data_preprocessed\\Training\\input\n",
      "[2025-02-07 23:03:54,521]: INFO: common : Directory has been Created: artifact\\data_preprocessed\\Training\\output\n",
      "[2025-02-07 23:03:54,522]: INFO: common : Directory has been Created: artifact\\data_preprocessed\\Testing\\input\n",
      "[2025-02-07 23:03:59,741]: INFO: 3545950779 : Training Dataframe has been Created\n",
      "[2025-02-07 23:03:59,855]: INFO: 3545950779 : Testing Dataframe has been Created\n",
      "[2025-02-07 23:03:59,863]: INFO: 3545950779 : Training Dataframe has been Pre-processed\n",
      "[2025-02-07 23:03:59,863]: INFO: 3545950779 : Testing Dataframe has been Pre-processed\n",
      "[2025-02-07 23:14:39,925]: INFO: 3545950779 : Pre-Processed Input Training Data at: artifact/data_preprocessed/Training/input\n",
      "[2025-02-07 23:14:39,926]: INFO: 3545950779 : Pre-Processed Mask Training Data at: artifact/data_preprocessed/Training/output\n",
      "[2025-02-07 23:18:35,849]: INFO: 3545950779 : Pre-Processed Input Testing Data at: artifact/data_preprocessed/Testing/input\n",
      "[2025-02-07 23:18:35,867]: INFO: 3545950779 : Training Dataset CSV File at: artifact/data_preprocessed/train.csv\n",
      "[2025-02-07 23:18:35,870]: INFO: 3545950779 : Testing Dataset CSV File at: artifact/data_preprocessed/test.csv\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_processing_config = config.data_preprocessing_config()\n",
    "    data_preprocessing = DataPreprocessing(data_processing_config)\n",
    "    data_preprocessing.preprocess_dataset()\n",
    "except Exception as e:\n",
    "    e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"artifact/data_preprocessed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
